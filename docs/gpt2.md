# Model
1. [**GPT2: Language Models are Unsupervised Multitask Learners**](https://openai.com/research/better-language-models)
2. [openai-gpt2-model.py](https://github.com/openai/gpt-2/blob/master/src/model.py)
3. [HF-transformer-gpt2](https://huggingface.co/docs/transformers/model_doc/gpt2)
   
## Model-Architecture

# 笔记：
- [**nanoGPT**](https://colab.research.google.com/drive/1pY8-ql-koaE2fUTB3zRqQQ9pWkPT0bCs?usp=sharing)


# 参考：
1. https://jalammar.github.io/illustrated-word2vec/
2. https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
3. https://jalammar.github.io/illustrated-transformer/
4. https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/Conv1d_Predict_house_prices.ipynb
5. https://jalammar.github.io/illustrated-gpt2/
