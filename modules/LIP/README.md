# LIP(Language Image Pre-Trainning)
a neural network trained on a variety of (image, text) pairs to embedding for text-image task(image-text similarity retrieval and for zero-shot image classification). more use in VLM

## CLIP
- [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) (CLIP: Contrastive Language-Image Pre-Training)
- https://github.com/openai/CLIP
- https://huggingface.co/docs/transformers/model_doc/clip

## SigLIP
- [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343) (SigLIP)
- https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py
- https://huggingface.co/docs/transformers/model_doc/siglip
