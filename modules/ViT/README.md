# reference
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- https://github.com/google-research/vision_transformer
- https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py
- https://github.com/lucidrains/vit-pytorch


------

use transformer encoder, BERT (for nlp task, predict)
- [BERT: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805)
- https://github.com/google-research/bert
- https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A02-Transformer%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86/2.3-%E5%9B%BE%E8%A7%A3BERT.md